<!DOCTYPE HTML>
<html>

<head>
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><link rel="bookmark"  type="image/x-icon"  href="img/favicon.ico"/>
	<link rel="shortcut icon" href="img/favicon.ico">
	
			    <title>
    文艺与Code | Thinkgamer的博客
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="Thinkgamer Hadoop 数据挖掘 机器学习 深度学习 IT网站 博客" />
    
    	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
	
</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">Thinkgamer</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">主页</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">分类</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/数据计算/">数据计算</a></li><li><a class="category-link" href="/categories/机器学习/">机器学习</a></li><li><a class="category-link" href="/categories/编程珠玑/">编程珠玑</a></li><li><a class="category-link" href="/categories/这夏未眠/">这夏未眠</a></li><li><a class="category-link" href="/categories/随手记/">随手记</a>
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/tag/" title="标签">
		                标签
		            </a>
		        </li>
		        
		        <li>
		            <a href="/about/" title="关于我">
		                关于我
		            </a>
		        </li>
		        
		        <li>
		            <a href="/cooperation/" title="商务合作">
		                商务合作
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
		            
		                <li><a href="https://github.com/thinkgamer" class="icon fa-github"><span class="label">GitHub</span></a></li>
		            
		            
		            
		            
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(/images/thumbs/ml2.jpg);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >梯度算法之批量梯度下降，随机梯度下降和小批量梯度下降</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <p>在机器学习领域，体梯度下降算法分为三种</p>
<ul>
<li>批量梯度下降算法（BGD，Batch gradient descent algorithm）</li>
<li>随机梯度下降算法（SGD，Stochastic gradient descent algorithm）</li>
<li>小批量梯度下降算法（MBGD，Mini-batch gradient descent algorithm）</li>
</ul>
<a id="more"></a>
<h1 id="批量梯度下降算法"><a href="#批量梯度下降算法" class="headerlink" title="批量梯度下降算法"></a>批量梯度下降算法</h1><p>BGD是最原始的梯度下降算法，每一次迭代使用全部的样本，即权重的迭代公式中(公式中用$\theta$代替$\theta_i$)，</p>
<script type="math/tex; mode=display">
\jmath (\theta _0,\theta _1,...,\theta _n)=\sum_{i=0}^{m}( h_\theta(x_0,x_1,...,x_n)-y_i )^2</script><script type="math/tex; mode=display">
\theta _i = \theta _i - \alpha \frac{\partial \jmath (\theta _1,\theta _2,...,\theta _n)}{\partial \theta _i}</script><script type="math/tex; mode=display">
公式(1)</script><p>这里的m代表所有的样本，表示从第一个样本遍历到最后一个样本。</p>
<p>特点：</p>
<ul>
<li>能达到全局最优解，易于并行实现</li>
<li>当样本数目很多时，训练过程缓慢</li>
</ul>
<h1 id="随机梯度下降算法"><a href="#随机梯度下降算法" class="headerlink" title="随机梯度下降算法"></a>随机梯度下降算法</h1><p>SGD的思想是更新每一个参数时都使用一个样本来进行更新，即公式（1）中m为1。每次更新参数都只使用一个样本，进行多次更新。这样在样本量很大的情况下，可能只用到其中的一部分样本就能得到最优解了。<br>但是，SGD伴随的一个问题是噪音较BGD要多，使得SGD并不是每次迭代都向着整体最优化方向。</p>
<p>特点：</p>
<ul>
<li>训练速度快</li>
<li>准确度下降，并不是最优解，不易于并行实现</li>
</ul>
<h1 id="小批量梯度下降算法"><a href="#小批量梯度下降算法" class="headerlink" title="小批量梯度下降算法"></a>小批量梯度下降算法</h1><p>MBGD的算法思想就是在更新每一参数时都使用一部分样本来进行更新，也就是公式（1）中的m的值大于1小于所有样本的数量。</p>
<p>相对于随机梯度下降，Mini-batch梯度下降降低了收敛波动性，即降低了参数更新的方差，使得更新更加稳定。相对于批量梯度下降，其提高了每次学习的速度。并且其不用担心内存瓶颈从而可以利用矩阵运算进行高效计算。一般而言每次更新随机选择[50,256]个样本进行学习，但是也要根据具体问题而选择，实践中可以进行多次试验，选择一个更新速度与更次次数都较适合的样本数。mini-batch梯度下降可以保证收敛性，常用于神经网络中。</p>
<h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>在样本量较小的情况下，可以使用批量梯度下降算法，样本量较大的情况或者线上，可以使用随机梯度下降算法或者小批量梯度下降算法。</p>
<p>在机器学习中的无约束优化算法，除了梯度下降以外，还有前面提到的最小二乘法，此外还有牛顿法和拟牛顿法。</p>
<p>梯度下降法和最小二乘法相比，梯度下降法需要选择步长，而最小二乘法不需要。梯度下降法是迭代求解，最小二乘法是计算解析解。如果样本量不算很大，且存在解析解，最小二乘法比起梯度下降法要有优势，计算速度很快。但是如果样本量很大，用最小二乘法由于需要求一个超级大的逆矩阵，这时就很难或者很慢才能求解解析解了，使用迭代的梯度下降法比较有优势。</p>
<p>梯度下降法和牛顿法/拟牛顿法相比，两者都是迭代求解，不过梯度下降法是梯度求解，而牛顿法/拟牛顿法是用二阶的海森矩阵的逆矩阵或伪逆矩阵求解。相对而言，使用牛顿法/拟牛顿法收敛更快。但是每次迭代的时间比梯度下降法长。</p>
<h1 id="sklearn中的SGD"><a href="#sklearn中的SGD" class="headerlink" title="sklearn中的SGD"></a>sklearn中的SGD</h1><p>sklearn官网上查了一下，并没有找到BGD和MBGD的相关文档，只是看到可SGD的，感兴趣的可以直接去官网看英文文档，点击SGD查看：<a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html" target="_blank" rel="external">SGD</a>，这也有一个中文的 <a href="http://sklearn.lzjqsdd.com/modules/sgd.html" target="_blank" rel="external">SGD</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">In [1]: from sklearn.linear_model import SGDClassifier</span><br><span class="line"></span><br><span class="line">In [2]: X = [[0., 0.], [1., 1.]]</span><br><span class="line"></span><br><span class="line">In [3]: y = [0, 1]</span><br><span class="line"></span><br><span class="line">In [4]: clf = SGDClassifier(loss=&quot;hinge&quot;, penalty=&quot;l2&quot;)</span><br><span class="line"></span><br><span class="line">In [5]: clf.fit(X, y)</span><br><span class="line">Out[5]: </span><br><span class="line">SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,</span><br><span class="line">       eta0=0.0, fit_intercept=True, l1_ratio=0.15,</span><br><span class="line">       learning_rate=&apos;optimal&apos;, loss=&apos;hinge&apos;, n_iter=5, n_jobs=1,</span><br><span class="line">       penalty=&apos;l2&apos;, power_t=0.5, random_state=None, shuffle=True,</span><br><span class="line">       verbose=0, warm_start=False)</span><br><span class="line"></span><br><span class="line">In [6]:  clf.predict([[2., 2.]])</span><br><span class="line">Out[6]: array([1])</span><br><span class="line"></span><br><span class="line">In [7]: clf.coef_ </span><br><span class="line">Out[7]: array([[ 9.91080278,  9.91080278]])</span><br><span class="line"></span><br><span class="line">In [8]: clf.intercept_ </span><br><span class="line">Out[8]: array([-9.97004991])</span><br></pre></td></tr></table></figure>
<p>参考：</p>
<ul>
<li><a href="https://www.cnblogs.com/pinard/p/5970503.html" target="_blank" rel="external">https://www.cnblogs.com/pinard/p/5970503.html</a></li>
<li><a href="http://blog.csdn.net/uestc_c2_403/article/details/74910107" target="_blank" rel="external">http://blog.csdn.net/uestc_c2_403/article/details/74910107</a></li>
</ul>
<hr>
<center>
    <img src="/img/gzh.jpg" weight="250px" height="250px">
    <br>
    打开微信扫一扫，关注微信公众号【数据与算法联盟】
    <br>
    <br>
    <img src="/img/weixin.png" weight="250px" height="300px">
    <br>
    打开微信扫一扫，加小编好友，拉你进数据算法交流群

</center>
            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://yoursite.com/2017/12/14/机器学习/梯度算法之批量梯度下降，随机梯度下降和小批量梯度下降/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://yoursite.com/2017/12/14/机器学习/梯度算法之批量梯度下降，随机梯度下降和小批量梯度下降/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://hexo.io/zh-cn/" style="border-bottom: none;">hexo</a></li>
                <li>Design: <a href="http://miccall.tech " style="border-bottom: none;">miccall</a></li>
            </ul>
            
            	<span id="busuanzi_container_site_pv">2018总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>



 	
</html>
